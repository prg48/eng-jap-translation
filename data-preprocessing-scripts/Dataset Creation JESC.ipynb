{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers[sentencepiece] datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the japanese english dataset from JESC\n",
    "!wget \"https://object.pouta.csc.fi/OPUS-JESC/v2019-12-05/tmx/en-ja.tmx.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip file\n",
    "!gunzip en-ja.tmx.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install xmltodict file\n",
    "!pip install xmltodict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tmx file and convert to dictionary\n",
    "import xmltodict\n",
    "\n",
    "# Load the TMX file and convert it to a dictionary\n",
    "with open('en-ja.tmx') as file:\n",
    "    tmx = xmltodict.parse(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract each english and japanese translations to an english and japanese list\n",
    "all_english = []\n",
    "all_japanese = []\n",
    "\n",
    "for seg in tmx[\"tmx\"][\"body\"][\"tu\"]:\n",
    "  if seg[\"tuv\"][0][\"@xml:lang\"] == 'en':\n",
    "    english = seg[\"tuv\"][0][\"seg\"]\n",
    "    all_english.append(english)\n",
    "  else:\n",
    "    japanese = seg[\"tuv\"][0][\"seg\"]\n",
    "    all_japanese.append(japanese)\n",
    "\n",
    "  if seg[\"tuv\"][1][\"@xml:lang\"]== 'en':\n",
    "    english = seg[\"tuv\"][1][\"seg\"]\n",
    "    all_english.append(english)\n",
    "  else:\n",
    "    japanese = seg[\"tuv\"][1][\"seg\"]\n",
    "    all_japanese.append(japanese)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# create a dataframe of the english and japanese sentences\n",
    "df = pd.DataFrame({'en': all_english, 'jp': all_japanese})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the pandas dataframe as a dataset\n",
    "from datasets import Dataset\n",
    "\n",
    "save_location = \"drive/MyDrive/Language_translation/data/en-jp-JESC\"\n",
    "lang_dataset = Dataset.from_pandas(\n",
    "    df,\n",
    "    split=\"train\"\n",
    ")\n",
    "lang_dataset.save_to_disk(save_location)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
